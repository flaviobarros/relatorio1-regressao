---
title: "Relatório 1 - Regressão"
author: "Flavio Margarito Martins de Barros \n Gabriel Tupinamba da Cunha Leandro \n Gustavo Leite Machado"
date: "14/05/2022"
output: pdf_document
header-includes:
- \newcommand{\Minimize}{\mathop{\mathrm{Minimize}}\limits}
- \usepackage[brazil]{babel}
- \usepackage{bbm}
- \usepackage{amsmath}
- \usepackage{mathtools}
- \usepackage{mathrsfs}
- \usepackage[makeroom]{cancel}
- \usepackage{xcolor}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Conjunto de dados

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r echo=TRUE, warning=FALSE, message=FALSE}
## Carregando os pacotes
require(readxl)
require(corrplot)
require(psych)
require(kableExtra)
require(caret)
require(car)
require(GGally)
require(ggplot2)
```

## Descrição básica dos dados
```{r echo=TRUE, cache=TRUE}
## Lendo o banco de dados
## Fonte: https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength
dados <- read_excel(path = "Concrete_Data.xls", sheet = 1)

## Trocando os nomes das variáveis para o português
colnames(dados) <-
  c(
    "cimento",
    "escoria",
    "cinza",
    "agua",
    "super_plastificante",
    "agregador_grosso",
    "agregador_fino",
    "idade",
    "forca_compressiva"
  )


## Sumario dos dados
describe(dados)

sum(is.na(data.frame(dados)))


ggplot(dados, aes(x = forca_compressiva)) +
  geom_histogram(aes(y=..density..)) +
  geom_density(alpha=.2, fill="#FF6666") 



```

* Cimento               (kg / m3)
* Escoria               (kg / m3)
* Cinza                 (kg / m3)
* Agua                  (kg / m3)
* Super plastificante   (kg / m3)
* Agregadro grosso      (kg / m3)
* Agregador fino        (kg / m3)
* Idade                          (Dias 1~365)
* Força compressiva (Target)     (MPa) 

> Como podemos notar, temos 1030 observações, 8 variáveis explicativas e nossa variável de interesse (força compressiva), e nenhum dado faltante nas observações.
Pela descrição básica dos dados, não temos nenhum dado que parece fugir dos valores esperados (por exemplo: não temos valores negativos).

> Analisando a nossa variável resposta podemos notar que sua distribuição se assemelha a uma normal

## Preparação dos dados
```{r, echo=TRUE, cache=TRUE}
## Separando o conjunto de dados em treino e teste
set.seed(2)
inTrain <- createDataPartition(dados$forca_compressiva, p = 7/10)[[1]]
treino <- dados[inTrain,]
teste <- dados[-inTrain,]

## Mantendo casos completos em treino e teste
treino <- treino[complete.cases(treino),]
teste <- teste[complete.cases(teste),]


## Criando dataset normalizado para avaliar diferença de resultado
normalized_train <- treino
normalized_teste <- teste

maxTrainFeatures <- apply(normalized_train[,1:8], 2, max) #max of each feature
minTrainFeatures <- apply(normalized_train[,1:8], 2, min) #min of each feature


minMaxDiffTrain <- (maxTrainFeatures - minTrainFeatures)
minMaxDiffTrain

normalized_train[,1:8] <- sweep(normalized_train[,1:8], 2, minTrainFeatures, "-")
normalized_train[,1:8] <- sweep(normalized_train[,1:8], 2, minMaxDiffTrain, "/")

normalized_teste[,1:8] <- sweep(normalized_teste[,1:8], 2, minTrainFeatures, "-")
normalized_teste[,1:8] <- sweep(normalized_teste[,1:8], 2, minMaxDiffTrain, "/")


## Separando a variavel resposta, categóricas e numericas
# resposta <- treino$forca_compressiva
# resposta_teste <- teste$forca_compressiva

# ## Removendo a variável resposta
# treino <- treino[,-ncol(treino)]
# teste <- teste[,-ncol(teste)]

## Retendo as numéricas
Ind_numericas <- colnames(treino)[sapply(treino, is.numeric)]
Ind_categoricas <- colnames(treino)[sapply(treino, function(x) !is.numeric(x))]
numericas <- treino[,Ind_numericas]
categorias <- treino[,Ind_categoricas]
```


## Redução de dimensionalidade

```{r echo=TRUE}
## Analisando as correlações
M <- cor(numericas, use = 'complete.obs')
corrplot(M, method='number', diag = T, number.cex = 0.8)
summary(M[upper.tri(M)])

## Imprimindo as correlações na forma de circulos
M <- cor(numericas, use = 'complete.obs')
summary(M[upper.tri(M)])
corrplot(M, method='circle')

## Visualizando as correlações
ggpairs(numericas)


## Análise de Multicolinearidade


modelo1 <- lm(forca_compressiva ~., data = treino)

vif(modelo1)


```

>Como podemos notar, não temos uma correlação muita alta (pensando em módulo) entre as covariáveis. Entretanto, mesmo que tivéssemos, provavelmente não poderíamos remover alguma delas, pois, todas podem ser importantes, seja em termos químicos, seja em termos legas/legislativos. \linebreak
 Dependendo do objetivo da análise, se queremos acertar o valor da força compressevia de uma certa batelagem de cimento, ou do cimento utilizado em uma certa obra, ou se apenas queremos entender como essas variáveis influenciam na força compressiva, temos mais ou menos liberdades para modificar as covariáveis. \linebreak


> Como não temos variáveis altamente correlacionadas, provavelmente não teremos multicolinearidade, e ainda que tívessemos, provavelmente não poderíamos remover covariáveis da análise, entretando, vamos verificar mesmo assim. /linebreak
Para esse teste de multicolinearidade vamos utilizar a função vif (variance inflation factor) do pacote car. /linebreak
Como não temos valores muito altos (a cima de 10) de vif para nenhuma das covariáveis, vamos assumir que não sofremos do problema de multicolinearidade

## Detecção de Outliers

```{r echo=TRUE}
## Outliers em X

X <- X <- treino[, 1:8] #subset(treino, select = -c("forca_compressiva"))

H <- data.matrix(X) %*% solve((t(data.matrix(X)) %*% data.matrix(X))) %*% t(data.matrix(X))

hbar <- sum(diag(H)) / nrow(X)

criterio_oulier <- 2*hbar

sum(diag(H) > criterio_oulier)


sum(diag(H) > 0.5)

sum((diag(H) < criterio_oulier) & ((diag(H) > 0.2)))

sum(diag(H) < 0.2) / nrow(X)


outlierTest(modelo1)

```

> Por esse método temos possíveis 55 outliers
> Entretando, utilizando critérios alternativos:

* h_ii > 0.5 outlier
* 0.2 < h_ii < 0.5 Moderad -> analisar
* h_ii < 0.2 não é outlier

> Temos que todos os valores de diag(H) são inferiores a 0.2.

>Agora, utilizando a função outliers do pacote car, temos o seguinte:

* Utilizando o mesmo modelo que foi utilizado para a análise de multicolinearidade, não temos nenhum ponto que possa ser considerado um outlier.

> Logo, como em 2 dos 3 testes não temos nenhum ponto identificado como outlier, vamos considerar que não temos nenhuma observação que deveríamos considerar outlier


## Modelagem
```{r echo=TRUE}

f1 <-
  formula(
    forca_compressiva ~ cimento + escoria + cinza + agua +
      super_plastificante + agregador_grosso +
      agregador_fino + idade
  )


f1_log <-
  formula(
    log(forca_compressiva) ~ cimento + escoria + cinza + agua +
      super_plastificante + agregador_grosso +
      agregador_fino + idade
  )

f2 <- formula(
  forca_compressiva ~ cimento + escoria + cinza + agua +
    super_plastificante + agregador_grosso + agregador_fino + idade +
    I(cimento ^ 2) + I(escoria ^ 2) + I(cinza ^ 2) +
    I(agua ^ 2) + I(super_plastificante ^2) +
    I(agregador_grosso ^ 2) + I(agregador_fino ^ 2) + I(idade ^ 2)
  )

f2_log <- formula(
  log(forca_compressiva) ~ cimento + escoria + cinza + agua +
    super_plastificante + agregador_grosso + agregador_fino + idade +
    I(cimento ^ 2) + I(escoria ^ 2) + I(cinza ^ 2) +
    I(agua ^ 2) + I(super_plastificante ^2) +
    I(agregador_grosso ^ 2) + I(agregador_fino ^ 2) + I(idade ^ 2)
  )

formulas <- c(f1, f2)


for (f in formulas) {
  ##model
  model <- lm(formula = f, data=treino)
  
  model_norm <- lm(formula = f, data=normalized_train)
  
  ##predicao treino
  treinoPred     <- predict(model, treino)
  treinoPredNorm <- predict(model_norm, normalized_train)
  
  ##predicao teste
  testePred     <- predict(model, teste)
  testePredNorm <- predict(model_norm, normalized_teste)
  
  
  mae_treino  <- round(MAE(treino$forca_compressiva, treinoPred), 3)
  mae_teste   <- round(MAE(teste$forca_compressiva, testePred), 3)
  
  
  rmse_treino <- round(RMSE(treino$forca_compressiva, treinoPred), 3)
  rmse_teste  <- round(RMSE(teste$forca_compressiva, testePred), 3)
  
  
  mae_norm_treino  <- round(MAE(normalized_train$forca_compressiva, treinoPredNorm), 3)
  mae_norm_teste   <- round(MAE(normalized_teste$forca_compressiva, testePredNorm), 3)
  
  rmse_norm_treino <- round(RMSE(normalized_train$forca_compressiva, treinoPredNorm), 3)
  rmse_norm_teste  <- round(RMSE(normalized_teste$forca_compressiva, testePredNorm), 3)
  
  print(f)
  
  print(paste0('DATASET NÂO NORMALIZADO (TREINO -- TESTE): \n'))
  print(paste0('MAE :', mae_treino, ' --  ', mae_teste))
  print(paste0('RMSE :', rmse_treino, ' -- ', rmse_teste))

  print(paste0('DATASET NORMALIZADO (TREINO -- TESTE): \n'))
  print(paste0('MAE :', mae_norm_teste, ' -- ', mae_norm_teste))
  print(paste0('RMSE :', rmse_norm_treino, ' -- ', rmse_norm_teste))
  
  print('MUDANDO DE MODELO')
  print('')
  print('')
  print('')

}

formulas_log <- c(f1_log, f2_log)

for (f in formulas_log) {
  ##model
  model <- lm(formula = f, data=treino)
  
  model_norm <- lm(formula = f, data=normalized_train)
  
  ##predicao treino
  treinoPred     <- predict(model, treino)
  treinoPredNorm <- predict(model_norm, normalized_train)
  
  ##predicao teste
  testePred     <- predict(model, teste)
  testePredNorm <- predict(model_norm, normalized_teste)
  
  
  mae_treino  <- round(MAE(log(treino$forca_compressiva), treinoPred), 3)
  mae_teste   <- round(MAE(log(teste$forca_compressiva), testePred), 3)
  
  
  rmse_treino <- round(RMSE(log(treino$forca_compressiva), treinoPred), 3)
  rmse_teste  <- round(RMSE(log(teste$forca_compressiva), testePred), 3)
  
  
  mae_norm_treino  <- round(MAE(log(normalized_train$forca_compressiva), treinoPredNorm), 3)
  mae_norm_teste   <- round(MAE(log(normalized_teste$forca_compressiva), testePredNorm), 3)
  
  rmse_norm_treino <- round(RMSE(log(normalized_train$forca_compressiva), treinoPredNorm), 3)
  rmse_norm_teste  <- round(RMSE(log(normalized_teste$forca_compressiva), testePredNorm), 3)
  
  print(f)
  
  print(paste0('DATASET NÂO NORMALIZADO (TREINO -- TESTE): \n'))
  print(paste0('MAE :', mae_treino, ' --  ', mae_teste))
  print(paste0('RMSE :', rmse_treino, ' -- ', rmse_teste))
  
  print(paste0('DATASET NORMALIZADO (TREINO -- TESTE): \n'))
  print(paste0('MAE :', mae_norm_teste, ' -- ', mae_norm_teste))
  print(paste0('RMSE :', rmse_norm_treino, ' -- ', rmse_norm_teste))
  
  print('MUDANDO DE MODELO')
  print('')
  print('')
  print('')
  
}


```
>Temos aqui que aplicando o log na variável resposta, analisando MAE e RMSE, temos um melhor desempenho. Notamos também que normalizar ou não os dados fez pouca diferença, entretanto os modelos com termos quadráticos tiverem um melhor resultado

## Análise de Resíduos
```{r echo=TRUE}

### A partir do tópico anterior, selecionamos o modelo a baixo. Vamos utilizá-lo para fazer a análise de resíduos


final_model <- lm(formula = f1, data = treino)

e <- resid(final_model)


plot(log(treino$forca_compressiva), e,
     ylab="Resíduos", xlab="Valor Observado", 
     main="Análise de Resíduos") 
abline(0, 0)            
```
